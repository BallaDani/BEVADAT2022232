{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "1.  Értelmezd az adatokat!!!\n",
    "    A feladat megoldásához használd a NJ transit + Amtrack csv-t a moodle-ból.\n",
    "    A NJ-60k az a megoldott. Azt fogom használni a modellek teszteléséhez, illetve össze tudod hasonlítani az eredményedet.    \n",
    "\n",
    "2. Írj egy osztályt a következő feladatokra:  \n",
    "     2.1 Neve legyen NJCleaner és mentsd el a NJCleaner.py-ba. Ebben a fájlban csak ez az osztály legyen.\n",
    "     2.2 Konsturktorban kapja meg a csv elérési útvonalát és olvassa be pandas segítségével és mentsük el a data (self.data) osztályszintű változóba \n",
    "     2.3 Írj egy függvényt ami sorbarendezi a dataframe-et 'scheduled_time' szerint növekvőbe és visszatér a sorbarendezett df-el, a függvény neve legyen 'order_by_scheduled_time' és térjen vissza a df-el  \n",
    "     2.4 Dobjuk el a from és a to oszlopokat, illetve azokat a sorokat ahol van nan és adjuk vissza a df-et. A függvény neve legyen 'drop_columns_and_nan' és térjen vissza a df-el  \n",
    "     2.5 A date-et alakítsd át napokra, pl.: 2018-03-01 --> Thursday, ennek az oszlopnak legyen neve a 'day'. Ezután dobd el a 'date' oszlopot és térjen vissza a df-el. A függvény neve legyen 'convert_date_to_day' és térjen vissza a df-el   \n",
    "     2.6 Hozz létre egy új oszlopot 'part_of_the_day' névvel. A 'scheduled_time' oszlopból számítsd ki az alábbi értékeit. A 'scheduled_time'-ot dobd el. A függvény neve legyen 'convert_scheduled_time_to_part_of_the_day' és térjen vissza a df-el  \n",
    "         4:00-7:59 -- early_morning  \n",
    "         8:00-11:59 -- morning  \n",
    "         12:00-15:59 -- afternoon  \n",
    "         16:00-19:59 -- evening  \n",
    "         20:00-23:59 -- night  \n",
    "         0:00-3:59 -- late_night  \n",
    "    2.7 A késéseket jelöld az alábbiak szerint. Az új osztlop neve legyen 'delay'. A függvény neve legyen pedig 'convert_delay' és térjen vissza a df-el\n",
    "         0min <= x < 5min   --> 0  \n",
    "         5min <= x          --> 1  \n",
    "    2.8 Dobd el a felesleges oszlopokat 'train_id' 'actual_time' 'delay_minutes'. A függvény neve legyen 'drop_unnecessary_columns' és térjen vissza a df-el\n",
    "    2.9 Írj egy olyan metódust, ami elmenti a dataframe első 60 000 sorát. A függvénynek egy string paramétere legyen, az pedig az, hogy hova mentse el a csv-t (pl.: 'data/NJ.csv'). A függvény neve legyen 'save_first_60k'. \n",
    "    2.10 Írj egy függvényt ami a fenti függvényeket összefogja és megvalósítja (sorbarendezés --> drop_columns_and_nan --> ... --> save_first_60k), a függvény neve legyen 'prep_df'. Egy paramnétert várjon, az pedig a csv-nek a mentési útvonala legyen. Ha default value-ja legyen 'data/NJ.csv'\n",
    "\n",
    "3.  A feladatot a HAZI06.py-ban old meg.\n",
    "    Az órán megírt DecisionTreeClassifier-t fit-eld fel az első feladatban lementett csv-re. \n",
    "    A feladat célja az, hogy határozzuk meg azt, hogy a vonatok késnek-e vagy sem. 0p <= x < 5p --> nem késik (0), ha 5p <= x --> késik (1).\n",
    "    Az adatoknak a 20% legyen test és a splitelés random_state-je pedig 41 (mint órán)\n",
    "    A testset-en 80% kell elérni. Ha megvan a minimum százalék, akkor azzal paraméterezd fel a decisiontree-t és azt kell leadni.\n",
    "\n",
    "    A leadásnál csak egy fit kell, ezt azzal a paraméterre paraméterezd fel, amivel a legjobb accuracy-t elérted.\n",
    "\n",
    "    A helyes paraméter megtalálásához használhatsz grid_search-öt.\n",
    "    https://www.w3schools.com/python/python_ml_grid_search.asp \n",
    "\n",
    "4.  A tanításodat foglald össze 4-5 mondatban a HAZI06.py-ban a fájl legalján kommentben. Írd le a nehézségeket, mivel próbálkoztál, mi vált be és mi nem. Ezen kívül írd le 10 fitelésed eredményét is, hogy milyen paraméterekkel probáltad és milyen accuracy-t értél el. \n",
    "Ha ezt feladatot hiányzik, akkor nem fogadjuk el a házit!\n",
    "\n",
    "HAZI-\n",
    "    HAZI06-\n",
    "        -NJCleaner.py\n",
    "        -HAZI06.py\n",
    "\n",
    "##################################################################\n",
    "##                                                              ##\n",
    "## A feladatok közül csak a NJCleaner javítom unit test-el      ##\n",
    "## A decision tree-t majd manuálisan fogom lefuttatni           ##\n",
    "## NJCleaner - 10p, Tanítás - acc-nál 10%-ként egy pont         ##\n",
    "## Ha a 4. feladat hiányzik, akkor nem tudjuk elfogadni a házit ##\n",
    "##                                                              ##\n",
    "##################################################################\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              date train_id  stop_sequence                   from  from_id  \\\n",
      "0       2018-03-01     3805            1.0  New York Penn Station      105   \n",
      "1       2018-03-01     3805            2.0  New York Penn Station      105   \n",
      "2       2018-03-01     3805            3.0     Secaucus Upper Lvl    38187   \n",
      "3       2018-03-01     3805            4.0    Newark Penn Station      107   \n",
      "4       2018-03-01     3805            5.0         Newark Airport    37953   \n",
      "...            ...      ...            ...                    ...      ...   \n",
      "256503  2018-03-31     0534            2.0             Bay Street       14   \n",
      "256504  2018-03-31     0534            3.0             Glen Ridge       50   \n",
      "256505  2018-03-31     0534            4.0             Bloomfield       19   \n",
      "256506  2018-03-31     0534            5.0      Watsessing Avenue      154   \n",
      "256507  2018-03-31     0534            6.0    Newark Broad Street      106   \n",
      "\n",
      "                           to  to_id       scheduled_time  \\\n",
      "0       New York Penn Station    105  2018-03-02 01:22:00   \n",
      "1          Secaucus Upper Lvl  38187  2018-03-02 01:31:00   \n",
      "2         Newark Penn Station    107  2018-03-02 01:40:00   \n",
      "3              Newark Airport  37953  2018-03-02 01:45:00   \n",
      "4             North Elizabeth    109  2018-03-02 01:49:00   \n",
      "...                       ...    ...                  ...   \n",
      "256503             Glen Ridge     50  2018-03-31 19:02:00   \n",
      "256504             Bloomfield     19  2018-03-31 19:05:00   \n",
      "256505      Watsessing Avenue    154  2018-03-31 19:07:00   \n",
      "256506    Newark Broad Street    106  2018-03-31 19:13:00   \n",
      "256507                Hoboken     63  2018-03-31 19:38:00   \n",
      "\n",
      "                actual_time  delay_minutes     status               line  \\\n",
      "0       2018-03-02 01:21:05       0.000000   departed   Northeast Corrdr   \n",
      "1       2018-03-02 01:31:08       0.133333   departed   Northeast Corrdr   \n",
      "2       2018-03-02 01:40:07       0.116667   departed   Northeast Corrdr   \n",
      "3       2018-03-02 01:45:10       0.166667   departed   Northeast Corrdr   \n",
      "4       2018-03-02 01:49:10       0.166667   departed   Northeast Corrdr   \n",
      "...                     ...            ...        ...                ...   \n",
      "256503  2018-03-31 19:05:07       3.116667   departed  Montclair-Boonton   \n",
      "256504  2018-03-31 19:08:06       3.100000   departed  Montclair-Boonton   \n",
      "256505  2018-03-31 19:10:11       3.183333   departed  Montclair-Boonton   \n",
      "256506  2018-03-31 19:21:02       8.033333   departed  Montclair-Boonton   \n",
      "256507  2018-03-31 19:37:00       0.000000  estimated  Montclair-Boonton   \n",
      "\n",
      "              type  \n",
      "0       NJ Transit  \n",
      "1       NJ Transit  \n",
      "2       NJ Transit  \n",
      "3       NJ Transit  \n",
      "4       NJ Transit  \n",
      "...            ...  \n",
      "256503  NJ Transit  \n",
      "256504  NJ Transit  \n",
      "256505  NJ Transit  \n",
      "256506  NJ Transit  \n",
      "256507  NJ Transit  \n",
      "\n",
      "[256508 rows x 13 columns]\n"
     ]
    }
   ],
   "source": [
    "def readcsv(csv):\n",
    "    return pd.read_csv(csv)\n",
    "\n",
    "data=readcsv('data/2018_03.csv')\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              date train_id  stop_sequence                 from  from_id  \\\n",
      "5283    2018-03-01     3806            1.0              Trenton      148   \n",
      "1270    2018-03-01     0042            1.0          Port Jervis      123   \n",
      "5284    2018-03-01     3806            2.0              Trenton      148   \n",
      "208     2018-03-01     3202            1.0          Long Branch       74   \n",
      "5285    2018-03-01     3806            3.0             Hamilton    32905   \n",
      "...            ...      ...            ...                  ...      ...   \n",
      "256459  2018-03-31     A663            NaN              Trenton      148   \n",
      "256460  2018-03-31     A664            NaN         Philadelphia        1   \n",
      "256461  2018-03-31     A664            NaN         Philadelphia        1   \n",
      "256462  2018-03-31     A664            NaN              Trenton      148   \n",
      "256463  2018-03-31     A664            NaN  Newark Penn Station      107   \n",
      "\n",
      "                           to  to_id       scheduled_time  \\\n",
      "5283                  Trenton    148  2018-03-01 03:48:00   \n",
      "1270              Port Jervis    123  2018-03-01 03:50:00   \n",
      "5284                 Hamilton  32905  2018-03-01 03:54:00   \n",
      "208               Long Branch     74  2018-03-01 03:58:00   \n",
      "5285       Princeton Junction    125  2018-03-01 04:00:00   \n",
      "...                       ...    ...                  ...   \n",
      "256459           Philadelphia      1                  NaN   \n",
      "256460           Philadelphia      1                  NaN   \n",
      "256461                Trenton    148                  NaN   \n",
      "256462    Newark Penn Station    107                  NaN   \n",
      "256463  New York Penn Station    105                  NaN   \n",
      "\n",
      "                actual_time  delay_minutes    status              line  \\\n",
      "5283    2018-03-01 04:02:07      14.116667  departed  Northeast Corrdr   \n",
      "1270    2018-03-01 03:50:04       0.066667  departed  Bergen Co. Line    \n",
      "5284    2018-03-01 04:02:07       8.116667  departed  Northeast Corrdr   \n",
      "208     2018-03-01 03:58:01       0.016667  departed   No Jersey Coast   \n",
      "5285    2018-03-01 04:02:07       2.116667  departed  Northeast Corrdr   \n",
      "...                     ...            ...       ...               ...   \n",
      "256459  2018-03-31 11:20:08            NaN  departed          KEYSTONE   \n",
      "256460  2018-03-31 11:26:07            NaN  departed            Amtrak   \n",
      "256461  2018-03-31 12:07:04            NaN  departed            Amtrak   \n",
      "256462  2018-03-31 12:47:04            NaN  departed            Amtrak   \n",
      "256463  2018-03-31 13:01:11            NaN  departed            Amtrak   \n",
      "\n",
      "              type  \n",
      "5283    NJ Transit  \n",
      "1270    NJ Transit  \n",
      "5284    NJ Transit  \n",
      "208     NJ Transit  \n",
      "5285    NJ Transit  \n",
      "...            ...  \n",
      "256459      Amtrak  \n",
      "256460      Amtrak  \n",
      "256461      Amtrak  \n",
      "256462      Amtrak  \n",
      "256463      Amtrak  \n",
      "\n",
      "[256508 rows x 13 columns]\n"
     ]
    }
   ],
   "source": [
    "def order_by_scheduled_time(df):\n",
    "    return df.sort_values('scheduled_time')\n",
    "\n",
    "data=order_by_scheduled_time(data)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              date train_id  stop_sequence  from_id  to_id  \\\n",
      "5283    2018-03-01     3806            1.0      148    148   \n",
      "1270    2018-03-01     0042            1.0      123    123   \n",
      "5284    2018-03-01     3806            2.0      148  32905   \n",
      "208     2018-03-01     3202            1.0       74     74   \n",
      "5285    2018-03-01     3806            3.0    32905    125   \n",
      "...            ...      ...            ...      ...    ...   \n",
      "253745  2018-03-31     4705            7.0       15    141   \n",
      "256387  2018-03-31     0709           13.0      117     49   \n",
      "253746  2018-03-31     4705            8.0      141     79   \n",
      "253747  2018-03-31     4705            9.0       79    122   \n",
      "253748  2018-03-31     4705           10.0      122     13   \n",
      "\n",
      "             scheduled_time          actual_time  delay_minutes     status  \\\n",
      "5283    2018-03-01 03:48:00  2018-03-01 04:02:07      14.116667   departed   \n",
      "1270    2018-03-01 03:50:00  2018-03-01 03:50:04       0.066667   departed   \n",
      "5284    2018-03-01 03:54:00  2018-03-01 04:02:07       8.116667   departed   \n",
      "208     2018-03-01 03:58:00  2018-03-01 03:58:01       0.016667   departed   \n",
      "5285    2018-03-01 04:00:00  2018-03-01 04:02:07       2.116667   departed   \n",
      "...                     ...                  ...            ...        ...   \n",
      "253745  2018-04-01 03:04:00  2018-04-01 03:04:03       0.050000   departed   \n",
      "256387  2018-04-01 03:05:00  2018-04-01 03:04:00       0.000000  estimated   \n",
      "253746  2018-04-01 03:07:00  2018-04-01 03:08:07       1.116667   departed   \n",
      "253747  2018-04-01 03:13:00  2018-04-01 03:13:09       0.150000   departed   \n",
      "253748  2018-04-01 03:22:00  2018-04-01 03:21:00       0.000000  estimated   \n",
      "\n",
      "                    line        type  \n",
      "5283    Northeast Corrdr  NJ Transit  \n",
      "1270    Bergen Co. Line   NJ Transit  \n",
      "5284    Northeast Corrdr  NJ Transit  \n",
      "208      No Jersey Coast  NJ Transit  \n",
      "5285    Northeast Corrdr  NJ Transit  \n",
      "...                  ...         ...  \n",
      "253745   No Jersey Coast  NJ Transit  \n",
      "256387  Gladstone Branch  NJ Transit  \n",
      "253746   No Jersey Coast  NJ Transit  \n",
      "253747   No Jersey Coast  NJ Transit  \n",
      "253748   No Jersey Coast  NJ Transit  \n",
      "\n",
      "[243028 rows x 11 columns]\n"
     ]
    }
   ],
   "source": [
    "def drop_columns_and_nan(df):\n",
    "        data= df.drop(columns=['from', 'to']).dropna()        \n",
    "        return data\n",
    "\n",
    "data=drop_columns_and_nan(data)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       train_id  stop_sequence  from_id  to_id       scheduled_time  \\\n",
      "5283       3806            1.0      148    148  2018-03-01 03:48:00   \n",
      "1270       0042            1.0      123    123  2018-03-01 03:50:00   \n",
      "5284       3806            2.0      148  32905  2018-03-01 03:54:00   \n",
      "208        3202            1.0       74     74  2018-03-01 03:58:00   \n",
      "5285       3806            3.0    32905    125  2018-03-01 04:00:00   \n",
      "...         ...            ...      ...    ...                  ...   \n",
      "253745     4705            7.0       15    141  2018-04-01 03:04:00   \n",
      "256387     0709           13.0      117     49  2018-04-01 03:05:00   \n",
      "253746     4705            8.0      141     79  2018-04-01 03:07:00   \n",
      "253747     4705            9.0       79    122  2018-04-01 03:13:00   \n",
      "253748     4705           10.0      122     13  2018-04-01 03:22:00   \n",
      "\n",
      "                actual_time  delay_minutes     status              line  \\\n",
      "5283    2018-03-01 04:02:07      14.116667   departed  Northeast Corrdr   \n",
      "1270    2018-03-01 03:50:04       0.066667   departed  Bergen Co. Line    \n",
      "5284    2018-03-01 04:02:07       8.116667   departed  Northeast Corrdr   \n",
      "208     2018-03-01 03:58:01       0.016667   departed   No Jersey Coast   \n",
      "5285    2018-03-01 04:02:07       2.116667   departed  Northeast Corrdr   \n",
      "...                     ...            ...        ...               ...   \n",
      "253745  2018-04-01 03:04:03       0.050000   departed   No Jersey Coast   \n",
      "256387  2018-04-01 03:04:00       0.000000  estimated  Gladstone Branch   \n",
      "253746  2018-04-01 03:08:07       1.116667   departed   No Jersey Coast   \n",
      "253747  2018-04-01 03:13:09       0.150000   departed   No Jersey Coast   \n",
      "253748  2018-04-01 03:21:00       0.000000  estimated   No Jersey Coast   \n",
      "\n",
      "              type       day  \n",
      "5283    NJ Transit  Thursday  \n",
      "1270    NJ Transit  Thursday  \n",
      "5284    NJ Transit  Thursday  \n",
      "208     NJ Transit  Thursday  \n",
      "5285    NJ Transit  Thursday  \n",
      "...            ...       ...  \n",
      "253745  NJ Transit  Saturday  \n",
      "256387  NJ Transit  Saturday  \n",
      "253746  NJ Transit  Saturday  \n",
      "253747  NJ Transit  Saturday  \n",
      "253748  NJ Transit  Saturday  \n",
      "\n",
      "[243028 rows x 11 columns]\n"
     ]
    }
   ],
   "source": [
    "def convert_date_to_day(df) -> pd.DataFrame:\n",
    "        df['day'] = (pd.to_datetime(df['date'])).dt.day_name()\n",
    "        df = df.drop(columns=['date'])\n",
    "        \n",
    "        return df\n",
    "\n",
    "data=convert_date_to_day(data)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       train_id  stop_sequence  from_id  to_id          actual_time  \\\n",
      "5283       3806            1.0      148    148  2018-03-01 04:02:07   \n",
      "1270       0042            1.0      123    123  2018-03-01 03:50:04   \n",
      "5284       3806            2.0      148  32905  2018-03-01 04:02:07   \n",
      "208        3202            1.0       74     74  2018-03-01 03:58:01   \n",
      "5285       3806            3.0    32905    125  2018-03-01 04:02:07   \n",
      "...         ...            ...      ...    ...                  ...   \n",
      "253745     4705            7.0       15    141  2018-04-01 03:04:03   \n",
      "256387     0709           13.0      117     49  2018-04-01 03:04:00   \n",
      "253746     4705            8.0      141     79  2018-04-01 03:08:07   \n",
      "253747     4705            9.0       79    122  2018-04-01 03:13:09   \n",
      "253748     4705           10.0      122     13  2018-04-01 03:21:00   \n",
      "\n",
      "        delay_minutes     status              line        type       day  \\\n",
      "5283        14.116667   departed  Northeast Corrdr  NJ Transit  Thursday   \n",
      "1270         0.066667   departed  Bergen Co. Line   NJ Transit  Thursday   \n",
      "5284         8.116667   departed  Northeast Corrdr  NJ Transit  Thursday   \n",
      "208          0.016667   departed   No Jersey Coast  NJ Transit  Thursday   \n",
      "5285         2.116667   departed  Northeast Corrdr  NJ Transit  Thursday   \n",
      "...               ...        ...               ...         ...       ...   \n",
      "253745       0.050000   departed   No Jersey Coast  NJ Transit  Saturday   \n",
      "256387       0.000000  estimated  Gladstone Branch  NJ Transit  Saturday   \n",
      "253746       1.116667   departed   No Jersey Coast  NJ Transit  Saturday   \n",
      "253747       0.150000   departed   No Jersey Coast  NJ Transit  Saturday   \n",
      "253748       0.000000  estimated   No Jersey Coast  NJ Transit  Saturday   \n",
      "\n",
      "       part_of_the_day  \n",
      "5283        late_night  \n",
      "1270        late_night  \n",
      "5284        late_night  \n",
      "208         late_night  \n",
      "5285     early_morning  \n",
      "...                ...  \n",
      "253745      late_night  \n",
      "256387      late_night  \n",
      "253746      late_night  \n",
      "253747      late_night  \n",
      "253748      late_night  \n",
      "\n",
      "[243028 rows x 11 columns]\n"
     ]
    }
   ],
   "source": [
    "def convert_scheduled_time_to_part_of_the_day(df):\n",
    "        df['part_of_the_day'] = pd.to_datetime(df['scheduled_time']).dt.hour.apply(lambda time: 'early_morning' if time >= 4 and time < 8 else('morning' if time >= 8 and time < 12 else('afternoon' if time >= 12 and time < 16 else('evening' if time >= 16 and time < 20 else('night' if time >= 20 and time < 24 else('late_night'))))))\n",
    "        df= df.drop(columns=['scheduled_time'])        \n",
    "        return df\n",
    "\n",
    "data=convert_scheduled_time_to_part_of_the_day(data)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       train_id  stop_sequence  from_id  to_id          actual_time  \\\n",
      "5283       3806            1.0      148    148  2018-03-01 04:02:07   \n",
      "1270       0042            1.0      123    123  2018-03-01 03:50:04   \n",
      "5284       3806            2.0      148  32905  2018-03-01 04:02:07   \n",
      "208        3202            1.0       74     74  2018-03-01 03:58:01   \n",
      "5285       3806            3.0    32905    125  2018-03-01 04:02:07   \n",
      "...         ...            ...      ...    ...                  ...   \n",
      "253745     4705            7.0       15    141  2018-04-01 03:04:03   \n",
      "256387     0709           13.0      117     49  2018-04-01 03:04:00   \n",
      "253746     4705            8.0      141     79  2018-04-01 03:08:07   \n",
      "253747     4705            9.0       79    122  2018-04-01 03:13:09   \n",
      "253748     4705           10.0      122     13  2018-04-01 03:21:00   \n",
      "\n",
      "        delay_minutes     status              line        type       day  \\\n",
      "5283        14.116667   departed  Northeast Corrdr  NJ Transit  Thursday   \n",
      "1270         0.066667   departed  Bergen Co. Line   NJ Transit  Thursday   \n",
      "5284         8.116667   departed  Northeast Corrdr  NJ Transit  Thursday   \n",
      "208          0.016667   departed   No Jersey Coast  NJ Transit  Thursday   \n",
      "5285         2.116667   departed  Northeast Corrdr  NJ Transit  Thursday   \n",
      "...               ...        ...               ...         ...       ...   \n",
      "253745       0.050000   departed   No Jersey Coast  NJ Transit  Saturday   \n",
      "256387       0.000000  estimated  Gladstone Branch  NJ Transit  Saturday   \n",
      "253746       1.116667   departed   No Jersey Coast  NJ Transit  Saturday   \n",
      "253747       0.150000   departed   No Jersey Coast  NJ Transit  Saturday   \n",
      "253748       0.000000  estimated   No Jersey Coast  NJ Transit  Saturday   \n",
      "\n",
      "       part_of_the_day  delay  \n",
      "5283        late_night      1  \n",
      "1270        late_night      0  \n",
      "5284        late_night      1  \n",
      "208         late_night      0  \n",
      "5285     early_morning      0  \n",
      "...                ...    ...  \n",
      "253745      late_night      0  \n",
      "256387      late_night      0  \n",
      "253746      late_night      0  \n",
      "253747      late_night      0  \n",
      "253748      late_night      0  \n",
      "\n",
      "[243028 rows x 12 columns]\n"
     ]
    }
   ],
   "source": [
    "def convert_delay(df):\n",
    "        df['delay'] = df['delay_minutes'].apply(lambda x: 0 if x >= 0 and x < 5 else(1))\n",
    "        return df\n",
    "\n",
    "data=convert_delay(data)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        stop_sequence  from_id  to_id     status              line  \\\n",
      "5283              1.0      148    148   departed  Northeast Corrdr   \n",
      "1270              1.0      123    123   departed  Bergen Co. Line    \n",
      "5284              2.0      148  32905   departed  Northeast Corrdr   \n",
      "208               1.0       74     74   departed   No Jersey Coast   \n",
      "5285              3.0    32905    125   departed  Northeast Corrdr   \n",
      "...               ...      ...    ...        ...               ...   \n",
      "253745            7.0       15    141   departed   No Jersey Coast   \n",
      "256387           13.0      117     49  estimated  Gladstone Branch   \n",
      "253746            8.0      141     79   departed   No Jersey Coast   \n",
      "253747            9.0       79    122   departed   No Jersey Coast   \n",
      "253748           10.0      122     13  estimated   No Jersey Coast   \n",
      "\n",
      "              type       day part_of_the_day  delay  \n",
      "5283    NJ Transit  Thursday      late_night      1  \n",
      "1270    NJ Transit  Thursday      late_night      0  \n",
      "5284    NJ Transit  Thursday      late_night      1  \n",
      "208     NJ Transit  Thursday      late_night      0  \n",
      "5285    NJ Transit  Thursday   early_morning      0  \n",
      "...            ...       ...             ...    ...  \n",
      "253745  NJ Transit  Saturday      late_night      0  \n",
      "256387  NJ Transit  Saturday      late_night      0  \n",
      "253746  NJ Transit  Saturday      late_night      0  \n",
      "253747  NJ Transit  Saturday      late_night      0  \n",
      "253748  NJ Transit  Saturday      late_night      0  \n",
      "\n",
      "[243028 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "def drop_unnecessary_columns(df):\n",
    "        df = df.drop(columns=['train_id', 'actual_time', 'delay_minutes'])\n",
    "        \n",
    "        return df\n",
    "\n",
    "data=drop_unnecessary_columns(data)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_first_60k(path,df):\n",
    "        df.head(60000).to_csv(path)\n",
    "save_first_60k('data/NJ.csv',data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'scheduled_time'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[90], line 10\u001b[0m\n\u001b[0;32m      7\u001b[0m         drop_unnecessary_columns(data)\n\u001b[0;32m      8\u001b[0m         save_first_60k(path,data)\n\u001b[1;32m---> 10\u001b[0m prep_df()\n\u001b[0;32m     11\u001b[0m \u001b[39mprint\u001b[39m(data)\n",
      "Cell \u001b[1;32mIn[90], line 2\u001b[0m, in \u001b[0;36mprep_df\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mprep_df\u001b[39m(path:\u001b[39mstr\u001b[39m \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mNJ.csv\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m----> 2\u001b[0m         order_by_scheduled_time(data)\n\u001b[0;32m      3\u001b[0m         drop_columns_and_nan(data)\n\u001b[0;32m      4\u001b[0m         convert_date_to_day(data)\n",
      "Cell \u001b[1;32mIn[83], line 2\u001b[0m, in \u001b[0;36morder_by_scheduled_time\u001b[1;34m(df)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39morder_by_scheduled_time\u001b[39m(df):\n\u001b[1;32m----> 2\u001b[0m     \u001b[39mreturn\u001b[39;00m df\u001b[39m.\u001b[39;49msort_values(\u001b[39m'\u001b[39;49m\u001b[39mscheduled_time\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\util\\_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[0;32m    326\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m    327\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    328\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[0;32m    329\u001b[0m         stacklevel\u001b[39m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    330\u001b[0m     )\n\u001b[1;32m--> 331\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\core\\frame.py:6912\u001b[0m, in \u001b[0;36mDataFrame.sort_values\u001b[1;34m(self, by, axis, ascending, inplace, kind, na_position, ignore_index, key)\u001b[0m\n\u001b[0;32m   6908\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mlen\u001b[39m(by):\n\u001b[0;32m   6909\u001b[0m     \u001b[39m# len(by) == 1\u001b[39;00m\n\u001b[0;32m   6911\u001b[0m     by \u001b[39m=\u001b[39m by[\u001b[39m0\u001b[39m]\n\u001b[1;32m-> 6912\u001b[0m     k \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_label_or_level_values(by, axis\u001b[39m=\u001b[39;49maxis)\n\u001b[0;32m   6914\u001b[0m     \u001b[39m# need to rewrap column in Series to apply key function\u001b[39;00m\n\u001b[0;32m   6915\u001b[0m     \u001b[39mif\u001b[39;00m key \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   6916\u001b[0m         \u001b[39m# error: Incompatible types in assignment (expression has type\u001b[39;00m\n\u001b[0;32m   6917\u001b[0m         \u001b[39m# \"Series\", variable has type \"ndarray\")\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\core\\generic.py:1850\u001b[0m, in \u001b[0;36mNDFrame._get_label_or_level_values\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1844\u001b[0m     values \u001b[39m=\u001b[39m (\n\u001b[0;32m   1845\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maxes[axis]\n\u001b[0;32m   1846\u001b[0m         \u001b[39m.\u001b[39mget_level_values(key)  \u001b[39m# type: ignore[assignment]\u001b[39;00m\n\u001b[0;32m   1847\u001b[0m         \u001b[39m.\u001b[39m_values\n\u001b[0;32m   1848\u001b[0m     )\n\u001b[0;32m   1849\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1850\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key)\n\u001b[0;32m   1852\u001b[0m \u001b[39m# Check for duplicates\u001b[39;00m\n\u001b[0;32m   1853\u001b[0m \u001b[39mif\u001b[39;00m values\u001b[39m.\u001b[39mndim \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n",
      "\u001b[1;31mKeyError\u001b[0m: 'scheduled_time'"
     ]
    }
   ],
   "source": [
    "def prep_df(path:str = 'NJ.csv'):\n",
    "        order_by_scheduled_time(data)\n",
    "        drop_columns_and_nan(data)\n",
    "        convert_date_to_day(data)\n",
    "        convert_scheduled_time_to_part_of_the_day(data)\n",
    "        convert_delay(data)\n",
    "        drop_unnecessary_columns(data)\n",
    "        save_first_60k(path,data)\n",
    "\n",
    "prep_df()\n",
    "print(data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A HAZI06.py tartalma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node():\n",
    "    def __init__(self,feature_index=None,treshold=None,left=None,right=None,info_gain=None,value=None):\n",
    "        #leaf\n",
    "        self.value=value\n",
    "\n",
    "        #dis\n",
    "        self.feature_index=feature_index\n",
    "        self.treshold=treshold\n",
    "        self.left=left\n",
    "        self.right=right\n",
    "        self.info_gain=info_gain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTreeClassifier():\n",
    "    def __init__(self, min_samples_split=2, max_depth=2):\n",
    "        \n",
    "        self.root = None\n",
    "        \n",
    "        self.min_samples_split = min_samples_split \n",
    "        self.max_depth = max_depth\n",
    "        \n",
    "    def build_tree(self, dataset, curr_depth=0):\n",
    "        \n",
    "        X, Y = dataset[:,:-1], dataset[:,-1]\n",
    "        num_samples, num_features = np.shape(X)\n",
    "        if num_samples>=self.min_samples_split and curr_depth<=self.max_depth:\n",
    "            best_split = self.get_best_split(dataset, num_samples, num_features)\n",
    "            if best_split[\"info_gain\"]>0: \n",
    "                left_subtree = self.build_tree(best_split[\"dataset_left\"], curr_depth+1)\n",
    "                right_subtree = self.build_tree(best_split[\"dataset_right\"], curr_depth+1)\n",
    "                return Node(best_split[\"feature_index\"], best_split[\"threshold\"],\n",
    "                            left_subtree, right_subtree, best_split[\"info_gain\"])\n",
    "        \n",
    "\n",
    "        leaf_value = self.calculate_leaf_value(Y)\n",
    "        return Node(value=leaf_value)\n",
    "    \n",
    "    def get_best_split(self, dataset, num_samples, num_features):\n",
    "        ''' function to find the best split '''\n",
    "        \n",
    "        best_split = {}\n",
    "        max_info_gain = -float(\"inf\")\n",
    "        \n",
    "        for feature_index in range(num_features):\n",
    "            feature_values = dataset[:, feature_index]\n",
    "            possible_thresholds = np.unique(feature_values)\n",
    "            for threshold in possible_thresholds: \n",
    "                dataset_left, dataset_right = self.split(dataset, feature_index, threshold)\n",
    "                if len(dataset_left)>0 and len(dataset_right)>0:\n",
    "                    y, left_y, right_y = dataset[:, -1], dataset_left[:, -1], dataset_right[:, -1]\n",
    "                    curr_info_gain = self.information_gain(y, left_y, right_y, \"gini\")\n",
    "                    if curr_info_gain>max_info_gain:\n",
    "                        best_split[\"feature_index\"] = feature_index\n",
    "                        best_split[\"threshold\"] = threshold\n",
    "                        best_split[\"dataset_left\"] = dataset_left\n",
    "                        best_split[\"dataset_right\"] = dataset_right\n",
    "                        best_split[\"info_gain\"] = curr_info_gain\n",
    "                        max_info_gain = curr_info_gain\n",
    "                        \n",
    "        return best_split\n",
    "    \n",
    "    def split(self, dataset, feature_index, threshold):\n",
    "        dataset_left = np.array([row for row in dataset if row[feature_index]<=threshold])\n",
    "        dataset_right = np.array([row for row in dataset if row[feature_index]>threshold])\n",
    "        return dataset_left, dataset_right\n",
    "    \n",
    "    def information_gain(self, parent, l_child, r_child, mode=\"entropy\"):\n",
    "        weight_l = len(l_child) / len(parent)\n",
    "        weight_r = len(r_child) / len(parent)\n",
    "        if mode==\"gini\":\n",
    "            gain = self.gini_index(parent) - (weight_l*self.gini_index(l_child) + weight_r*self.gini_index(r_child))\n",
    "        else:\n",
    "            gain = self.entropy(parent) - (weight_l*self.entropy(l_child) + weight_r*self.entropy(r_child))\n",
    "        return gain\n",
    "    \n",
    "    def entropy(self, y):\n",
    "        class_labels = np.unique(y)\n",
    "        entropy = 0\n",
    "        for cls in class_labels:\n",
    "            p_cls = len(y[y == cls]) / len(y)\n",
    "            entropy += -p_cls * np.log2(p_cls)\n",
    "        return entropy\n",
    "    \n",
    "    def gini_index(self, y):\n",
    "        class_labels = np.unique(y)\n",
    "        gini = 0\n",
    "        for cls in class_labels:\n",
    "            p_cls = len(y[y == cls]) / len(y)\n",
    "            gini += p_cls**2\n",
    "        return 1 - gini\n",
    "        \n",
    "    def calculate_leaf_value(self, Y):\n",
    "        \n",
    "        Y = list(Y)\n",
    "        return max(Y, key=Y.count)\n",
    "    \n",
    "    def print_tree(self, tree=None, indent=\" \"):\n",
    "        \n",
    "        if not tree:\n",
    "            tree = self.root\n",
    "\n",
    "        if tree.value is not None:\n",
    "            print(tree.value)\n",
    "\n",
    "        else:\n",
    "            print(\"X_\"+str(tree.feature_index), \"<=\", tree.threshold, \"?\", tree.info_gain)\n",
    "            print(\"%sleft:\" % (indent), end=\"\")\n",
    "            self.print_tree(tree.left, indent + indent)\n",
    "            print(\"%sright:\" % (indent), end=\"\")\n",
    "            self.print_tree(tree.right, indent + indent)\n",
    "    \n",
    "    def fit(self, X, Y):\n",
    "        \n",
    "        dataset = np.concatenate((X, Y), axis=1)\n",
    "        self.root = self.build_tree(dataset)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \n",
    "        preditions = [self.make_prediction(x, self.root) for x in X]\n",
    "        return preditions\n",
    "    \n",
    "    def make_prediction(self, x, tree):\n",
    "        \n",
    "        if tree.value!=None: \n",
    "            return tree.value\n",
    "        feature_val = x[tree.feature_index]\n",
    "        if feature_val<=tree.threshold:\n",
    "            return self.make_prediction(x, tree.left)\n",
    "        else:\n",
    "            return self.make_prediction(x, tree.right)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_name = ['stop_sequence', 'from_id', 'to_id', 'status', 'line','type','day','delay']\n",
    "data = pd.read_csv(\"data/NJ.csv\", skiprows=1, header=None, names=col_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m x\u001b[39m=\u001b[39mdata\u001b[39m.\u001b[39miloc[:,\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39mvalues\n\u001b[0;32m      2\u001b[0m y\u001b[39m=\u001b[39mdata\u001b[39m.\u001b[39miloc[:,\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39mvalues\u001b[39m.\u001b[39mreshape(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m,\u001b[39m1\u001b[39m)\n\u001b[0;32m      3\u001b[0m x_train,x_test,y_train,y_test\u001b[39m=\u001b[39mtrain_test_split(x,y,test_size\u001b[39m=\u001b[39m\u001b[39m.2\u001b[39m,random_state\u001b[39m=\u001b[39m\u001b[39m42\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "x=data.iloc[:,-1].values\n",
    "y=data.iloc[:,-1].values.reshape(-1,1)\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=.2,random_state=42)\n",
    "classifier=DecisionTreeClassifier(min_samples_split=5,max_depth=5)\n",
    "classifier.fit(x_train,y_train)\n",
    "y_pred=classifier.predict(x_test)\n",
    "print(accuracy_score(y_test,y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
