{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node():\n",
    "    def __init__(self,feature_index=None,treshold=None,left=None,right=None,info_gain=None,value=None):\n",
    "        #leaf\n",
    "        self.value=value\n",
    "\n",
    "        #dis\n",
    "        self.feature_index=feature_index\n",
    "        self.treshold=treshold\n",
    "        self.left=left\n",
    "        self.right=right\n",
    "        self.info_gain=info_gain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "class DecisionTreeClassifier():\n",
    "    def __init__(self,min_sample_split=2,max_depth=2) -> None:\n",
    "        self.max_depth=max_depth\n",
    "        self.min_sample_split=min_sample_split\n",
    "\n",
    "        self.root=None\n",
    "    def build_tree(self,dataset,curr_depth=0):\n",
    "        X,Y=dataset[::-1],dataset[:,-1]\n",
    "\n",
    "        num_sample,num_feature=np.shape(X)\n",
    "\n",
    "        if  num_sample>=self.min_sample_split and curr_depth<=self.max_depth:\n",
    "            best_split=self.get_best_split(dataset,num_sample,num_feature)\n",
    "\n",
    "            if best_split['info_gain']>0:\n",
    "                left_subtree=self.build_tree(best_split['dataset_left'],curr_depth+1)\n",
    "                rigth_subtree=self.build_tree(best_split['dataset_rigth'],curr_depth+1)\n",
    "                return Node(best_split['feature_index'],best_split['treshold'],left_subtree,rigth_subtree,best_split['info_gain'])\n",
    "            \n",
    "            \n",
    "\n",
    "\n",
    "\n",
    "    def get_best_spli(self, dataset,num_sample,num_feature):\n",
    "        best_split=()\n",
    "        max_info_gain=float('inf')\n",
    "\n",
    "        for feature_index in range(num_feature):\n",
    "            feature_value=dataset[:,feature_index]\n",
    "            possible_treshold=np.unique(feature_value)\n",
    "\n",
    "            for treshold in possible_treshold:\n",
    "                dataset_left,dataset_rigth,=self.split(dataset, feature_index, treshold)\n",
    "                if len(dataset_left)>0 and len(dataset_rigth)>0:\n",
    "                    y,left_y,rigth_y=dataset[:-1],dataset_left[:-1],dataset_rigth[:-1]\n",
    "\n",
    "                    curr_info_gain=self.information_gain(y,left_y,rigth_y,'gini')\n",
    "\n",
    "                    if curr_info_gain>max_info_gain:\n",
    "                        best_split['feature_index']=feature_index\n",
    "                        best_split['treshold']=treshold\n",
    "                        best_split['dataset_left']=dataset_left\n",
    "                        best_split['dataset_rigth']=dataset_rigth\n",
    "                        best_split['info_gain']=curr_info_gain\n",
    "\n",
    "                        max_info_gain=curr_info_gain\n",
    "\n",
    "        return best_split\n",
    "    \n",
    "\n",
    "\n",
    "    def split(self,dataset,feature_index,treshold):\n",
    "        dataset_left=np.array([row for row in dataset if row[feature_index]<=treshold])\n",
    "        dataset_rigth=np.array([row for row in dataset if row[feature_index]>treshold])\n",
    "\n",
    "        return dataset_left,dataset_rigth\n",
    "    \n",
    "\n",
    "    def information_gain(self,parent,l_child,r_child,mode='entropy'):\n",
    "        weight_l=len(l_child)/len(parent)\n",
    "        weight_r=len(l_child)/len(parent)\n",
    "\n",
    "\n",
    "        gain=self.gini_index(parent)-(weight_l*self.gini_index(l_child)+weight_r*self.gini_index(r_child))\n",
    "\n",
    "        return gain\n",
    "\n",
    "    def gini_index(self,y):\n",
    "        class_labels=np.unique(y)\n",
    "        gini=0\n",
    "        for cls in class_labels:\n",
    "            p_cls=len(y[y==cls])/len(y)\n",
    "            gini+=p_cls**2\n",
    "\n",
    "        return 1-gini\n",
    "    def calculate_leaf_node(self,y):\n",
    "        y=list(y)\n",
    "        return max(y,key=(y.count))\n",
    "\n",
    "    def print_tree(self,tree=None,indent=\" \"):\n",
    "        if not tree:\n",
    "            tree=self.root\n",
    "\n",
    "        if tree.value is not None:\n",
    "            print(tree.value)\n",
    "        else:\n",
    "            print(\"x_\"+str(tree.feature_index),\"<=\",tree.treshold,\"?\", tree.info_gain)\n",
    "            print(\"%s left:\" %(indent),end=\"\")\n",
    "            self.print_tree(tree.left,indent=indent)\n",
    "            print(\"%s left:\" %(indent),end=\"\")     \n",
    "            self.print_tree(tree.left,indent=indent)\n",
    "\n",
    "    def fit(self,x,y):\n",
    "        dataset=np.concatenate((x,y),axis=1)\n",
    "        self.root=self.build_tree(dataset)\n",
    "\n",
    "    def predict(self,X):\n",
    "        prediciton=[self.make_prediction(x,self.root) for x in X]\n",
    "        return prediciton\n",
    "\n",
    "    def make_prediction(self,x,tree):\n",
    "        if  tree.value!=None:\n",
    "            return tree.value\n",
    "        feature_val=x[tree.feature_index]\n",
    "        if (feature_val<tree.treshold):\n",
    "            return self.make_prediction(x,tree.left)\n",
    "        else:\n",
    "            return self.make_prediction(x, tree.rigth)\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
